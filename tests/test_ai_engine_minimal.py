"""
Minimal Test for Central AI Engine (without PostgreSQL)
ØªØ³Øª Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„ Ù…ÙˆØªÙˆØ± AI (Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ PostgreSQL)
"""

import os
import sys

# Set PYTHONPATH
sys.path.insert(0, '/home/user/webapp/SecureRedLab')

print("\n" + "=" * 70)
print("  SecureRedLab - Central AI Engine Minimal Test")
print("  ØªØ³Øª Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„ Ù…ÙˆØªÙˆØ± Ù…Ø±Ú©Ø²ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")
print("=" * 70)

# Test 1: Import Classes
print("\n[TEST 1] Import Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§...")
try:
    from core.ai_core_engine import (
        AIModelType, ModelStatus, ActionType, SimulationType,
        AIModelConfig, Experience, ModelPerformanceMetrics
    )
    print("âœ… ØªÙ…Ø§Ù… Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Enum Ùˆ DataClass import Ø´Ø¯Ù†Ø¯")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± import: {e}")
    sys.exit(1)

# Test 2: Create Experience
print("\n[TEST 2] Ø³Ø§Ø®Øª ØªØ¬Ø±Ø¨Ù‡ (Experience)...")
try:
    exp = Experience(
        simulation_type=SimulationType.DDOS,
        state={'target': '192.168.1.1', 'intensity': 0.5},
        action=ActionType.INCREASE_INTENSITY,
        reward=0.8,
        next_state={'target': '192.168.1.1', 'intensity': 0.6},
        done=False,
        success=True
    )
    print(f"âœ… Experience Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯:")
    print(f"   - ID: {exp.experience_id[:8]}...")
    print(f"   - Type: {exp.simulation_type.value}")
    print(f"   - Action: {exp.action.value}")
    print(f"   - Reward: {exp.reward}")
    print(f"   - Success: {exp.success}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Experience: {e}")
    import traceback
    traceback.print_exc()

# Test 3: Model Config
print("\n[TEST 3] Ø³Ø§Ø®Øª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù…Ø¯Ù„...")
try:
    config = AIModelConfig(
        model_type=AIModelType.DEEPSEEK_CODER,
        model_path="/models/deepseek-coder-33b",
        priority=1,
        enabled=True,
        max_tokens=4096,
        temperature=0.7
    )
    print(f"âœ… Model Config Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯:")
    print(f"   - Type: {config.model_type.value}")
    print(f"   - Priority: {config.priority}")
    print(f"   - Enabled: {config.enabled}")
    print(f"   - Max Tokens: {config.max_tokens}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Config: {e}")
    import traceback
    traceback.print_exc()

# Test 4: Model Metrics
print("\n[TEST 4] Ø³Ø§Ø®Øª Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯...")
try:
    metrics = ModelPerformanceMetrics(
        model_type=AIModelType.LLAMA_3_1
    )
    
    # Simulate 5 requests
    for i in range(5):
        latency = 100 + (i * 10)
        confidence = 0.8 + (i * 0.02)
        success = i < 4  # 4 Ù…ÙˆÙÙ‚ØŒ 1 Ù†Ø§Ù…ÙˆÙÙ‚
        
        metrics.update(latency_ms=latency, confidence=confidence, success=success)
    
    print(f"âœ… Model Metrics Ø¨Ù‡â€ŒØ±ÙˆØ² Ø´Ø¯:")
    print(f"   - Total Requests: {metrics.total_requests}")
    print(f"   - Successful: {metrics.successful_requests}")
    print(f"   - Failed: {metrics.failed_requests}")
    print(f"   - Success Rate: {metrics.get_success_rate():.2%}")
    print(f"   - Avg Latency: {metrics.avg_latency_ms:.2f}ms")
    print(f"   - Avg Confidence: {metrics.avg_confidence:.2%}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Metrics: {e}")
    import traceback
    traceback.print_exc()

# Test 5: RL Core (without Database)
print("\n[TEST 5] ØªØ³Øª Ù‡Ø³ØªÙ‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªÙ‚ÙˆÛŒØªÛŒ (Ø¨Ø¯ÙˆÙ† DB)...")
try:
    from core.ai_core_engine import ReinforcementLearningCore
    
    # Ø¯Ø± Ø­Ø§Ù„Øª ØªØ³ØªØŒ Ø¨Ø§ÛŒØ¯ Ø§Ø² mock database Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…
    # ÙˆÙ„ÛŒ Ø§ÛŒÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù‡
    # ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· import Ø±Ùˆ ØªØ³Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    
    print("âš ï¸  RL Core Ù†ÛŒØ§Ø² Ø¨Ù‡ PostgreSQL Ø¯Ø§Ø±Ù‡ - skip Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…")
    print("   (Ø¯Ø± Ù…Ø­ÛŒØ· production Ø¨Ø§ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÙˆØ§Ù‚Ø¹ÛŒ ØªØ³Øª Ù…ÛŒâ€ŒØ´ÙˆØ¯)")
    
except Exception as e:
    print(f"âš ï¸  Ø®Ø·Ø§ÛŒ Ù…Ù†ØªØ¸Ø±Ù‡ (Ù†ÛŒØ§Ø² Ø¨Ù‡ PostgreSQL): {type(e).__name__}")

# Test 6: AI Model Manager (without Database)
print("\n[TEST 6] ØªØ³Øª Ù…Ø¯ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI...")
try:
    from core.ai_core_engine import AIModelManager
    
    print("âš ï¸  AI Model Manager Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø¯Ø§Ø±Ù‡")
    print("   ÙÙ‚Ø· import Ø±Ùˆ ØªØ³Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…...")
    
    # Import successful
    print("âœ… AIModelManager Ú©Ù„Ø§Ø³ Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª")
    
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± AI Model Manager: {e}")
    import traceback
    traceback.print_exc()

# Test 7: Experience to_dict and from_dict
print("\n[TEST 7] ØªØ³Øª ØªØ¨Ø¯ÛŒÙ„ Experience Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ...")
try:
    exp = Experience(
        simulation_type=SimulationType.SHELL_UPLOAD,
        state={'target': 'example.com'},
        action=ActionType.ADD_EVASION,
        reward=0.9,
        next_state={'target': 'example.com', 'uploaded': True},
        done=True,
        success=True
    )
    
    # Convert to dict
    exp_dict = exp.to_dict()
    print(f"âœ… Experience Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯:")
    print(f"   - Keys: {list(exp_dict.keys())}")
    print(f"   - Simulation Type: {exp_dict['simulation_type']}")
    print(f"   - Success: {exp_dict['success']}")
    
    # Convert back
    exp_restored = Experience.from_dict(exp_dict)
    print(f"âœ… Experience Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø´Ø¯:")
    print(f"   - Type Match: {exp_restored.simulation_type == exp.simulation_type}")
    print(f"   - Action Match: {exp_restored.action == exp.action}")
    print(f"   - Reward Match: {exp_restored.reward == exp.reward}")
    
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± serialization: {e}")
    import traceback
    traceback.print_exc()

# Test 8: Q-Learning Simulation (Mock)
print("\n[TEST 8] Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Q-Learning (Mock)...")
try:
    # Simulate Q-Table behavior without actual RL Core
    import json
    
    # Mock state
    state = {
        'target': '192.168.1.100',
        'open_ports': 3,
        'firewall': True
    }
    
    # Mock Q-values for different actions
    q_values = {
        'increase_intensity': 0.75,
        'decrease_intensity': 0.45,
        'change_strategy': 0.82,  # Best action
        'add_evasion': 0.68,
        'optimize_timing': 0.55,
        'stop_attack': 0.10
    }
    
    # Select best action
    best_action = max(q_values, key=q_values.get)
    best_q_value = q_values[best_action]
    
    print(f"âœ… Q-Learning Simulation:")
    print(f"   - State: {json.dumps(state, indent=6)}")
    print(f"   - Best Action: {best_action}")
    print(f"   - Best Q-Value: {best_q_value:.2f}")
    print(f"   - All Q-Values:")
    for action, q_val in sorted(q_values.items(), key=lambda x: -x[1])[:3]:
        print(f"      * {action}: {q_val:.2f}")
    
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Q-Learning sim: {e}")
    import traceback
    traceback.print_exc()

# Summary
print("\n" + "=" * 70)
print("  ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬")
print("=" * 70)
print("  âœ… Enum Classes: OK")
print("  âœ… DataClasses: OK")
print("  âœ… Experience Creation: OK")
print("  âœ… Model Config: OK")
print("  âœ… Performance Metrics: OK")
print("  âš ï¸  RL Core: Needs PostgreSQL (skipped)")
print("  âœ… Model Manager: Import OK")
print("  âœ… Serialization: OK")
print("  âœ… Q-Learning Mock: OK")
print("=" * 70)
print("\n  ğŸ‰ Central AI Engine Structure Verified!")
print("  âœ… Ú©Ø¯ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª (Ù†ÛŒØ§Ø² Ø¨Ù‡ PostgreSQL Ø¯Ø± production)")
print("=" * 70 + "\n")
